---
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

## Work breakdown

-   *Name1 Surname1*:
-   *Name2 Surname2*:
-   *Name3 Surname3*:

## Introduction

During the first three weeks, you learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

## Data description

```{r}
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidyr)
```

```{r}
list.files(getwd())
list.files("data/1-discrimination")
```

```{r}
test_path <- "test.csv"
train_path <- "train.csv"

stop_words <- read_file("stop_words.txt")
splitted_stop_words <- strsplit(stop_words, split='\n')
splitted_stop_words <- splitted_stop_words[[1]]
splitted_stop_words
```

```{r}
train <-  read.csv(file = train_path, stringsAsFactors = FALSE)
test <-  read.csv(file = test_path, stringsAsFactors = FALSE)
```

```{r}
num_discrim_tweets <- train %>%
filter(label == "discrim") %>%
nrow()

num_discrim_tweets
```

```{r}
discrimination_tweets <- train %>%
  filter(label == "discrim")

all_discrim_words <- discrimination_tweets %>%
unnest_tokens(word, tweet, token = "words") %>%
filter(!word %in% splitted_stop_words) %>%
nrow()

all_discrim_words
```

```{r}
num_neutral_tweets <- train %>%
filter(label == "neutral") %>%
nrow()

num_neutral_tweets
```

```{r}
neutral_tweets <- train %>%
  filter(label == "neutral")

all_neutral_words <- neutral_tweets %>%
unnest_tokens(word, tweet, token = "words") %>%
filter(!word %in% splitted_stop_words) %>%
nrow()

all_neutral_words
```

```{r}
unique_words <- train %>%
unnest_tokens(word, tweet, token = "words") %>%
filter(!word %in% splitted_stop_words) %>%
count(word, sort = TRUE) %>%
nrow()

unique_words
```

## Data visualization

Each time you work with some data, you need to understand it before you
start processing it. R has very powerful tools to make nice plots and
visualization. Show what are the most common words for negative and
positive examples as a histogram, word cloud etc. Be creative!

```{r}
# word_counts <- neutral_words %>%
#   count(splitted, name = "frequency") %>%
#   arrange(desc(frequency))
# 
# if (nrow(word_counts) > 0) {
#   top_words <- word_counts$splitted[1:15]
#   top_frequencies <- word_counts$frequency[1:15]
#   data_plot <- data.frame(top_words, top_frequencies)
#   palette <- heat.colors(15)
#  
#   ggplot(data_plot, aes(x = top_words, y = top_frequencies, fill = top_words)) +
#     geom_col() +
#     scale_fill_manual(values = palette) +
#     labs(title = "top 15 most frequent neutral words", x = "words", y = "count") +
#     theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
#     theme_light()
# } 

neutral_tweets <- train %>%
  filter(label == "neutral")

neutral_words <- neutral_tweets %>%
  unnest_tokens(word, tweet, token = "words") %>%
  filter(!word %in% splitted_stop_words)

word_counts <- neutral_words %>%
  count(word, name = "frequency") %>%
  arrange(desc(frequency))

if (nrow(word_counts) > 0) {
  top_words <- word_counts$word[1:15]
  top_frequencies <- word_counts$frequency[1:15]
  data_plot <- data.frame(top_words, top_frequencies)
  palette <- heat.colors(15)

  ggplot(data_plot, aes(x = top_words, y = top_frequencies, fill = top_words)) +
    geom_col() +
    scale_fill_manual(values = palette) +
    labs(title = "Top 15 Most Frequent Neutral Words", x = "Words", y = "Count") +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    theme_light()
}

```

```{r}
# word_counts <- discrim_words %>%
#   count(splitted, name = "frequency") %>%
#   arrange(desc(frequency))
# 
# if (nrow(word_counts) > 0) {
#   top_words <- word_counts$splitted[1:15]
#   top_frequencies <- word_counts$frequency[1:15]
#   data_plot <- data.frame(top_words, top_frequencies)
#   palette <- heat.colors(15)
#  
#   ggplot(data_plot, aes(x = top_words, y = top_frequencies, fill = top_words)) +
#     geom_col() +
#     scale_fill_manual(values = palette) +
#     labs(title = "top 15 most frequent discrimination words", x = "words", y = "count") +
#     theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
#     theme_light()
# } 

discrimination_tweets <- train %>%
  filter(label == "discrim")


discrim_words <- discrimination_tweets %>%
  unnest_tokens(word, tweet, token = "words") %>%
  filter(!word %in% splitted_stop_words)


word_counts <- discrim_words %>%
  count(word, name = "frequency") %>%
  arrange(desc(frequency))

if (nrow(word_counts) > 0) {
  top_words <- word_counts$word[1:15]
  top_frequencies <- word_counts$frequency[1:15]
  data_plot <- data.frame(top_words, top_frequencies)
  palette <- heat.colors(15)

  ggplot(data_plot, aes(x = top_words, y = top_frequencies, fill = top_words)) +
    geom_col() +
    scale_fill_manual(values = palette) +
    labs(title = "Top 15 Most Frequent Discrimination Words", x = "Words", y = "Count") +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    theme_light()
}

```

```{r}
discrim_count <- num_discrim_tweets 
neutral_count <- num_neutral_tweets 
categories <- data.frame(
  type = c("discrimination", "neutral"),
  count = c(discrim_count, neutral_count)
)

categories$percentage <- round((categories$count / sum(categories$count)) * 100, 1)
ggplot(categories, aes(x = "", y = count, fill = type)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y") + 
  geom_text(aes(label = paste(percentage, "%", sep = "")), 
            position = position_stack(vjust = 0.5)) + 
  labs(title = "distribution of discrimination and neutral words", fill = "type") +
  theme_void() +
  scale_fill_manual(values = c("discrimination" = "coral", "neutral" = "skyblue"))

```

## Classifier implementation

```{r}
naiveBayes <- setRefClass("naiveBayes",

       # Define fields to store intermediate results like frequency counts, probabilities, etc.
       fields = list(
           bag_of_words = "data.frame",          # Tokenized words and their counts
           class_word_counts = "data.frame",     # Word counts per class
           class_counts = "list",                # Number of instances for each class
           word_probabilities = "data.frame",    # Word probabilities given a class
           unseen_word_count = "numeric"         # Counter for unseen words in prediction
       ),

       methods = list(
                    fit = function(X, y)
                    {
                        training_data <- data.frame(text = X, label = y, stringsAsFactors = FALSE)
                        
                        unseen_word_count <<- 0
                    
                        bag_of_words <<- unnest_tokens(training_data, 'words', 'text', token = "words") %>%
                                        filter(!words %in% splitted_stop_words & !grepl("\\d", words))
                    
                        class_word_counts <<- bag_of_words %>%
                                              group_by(words, label) %>%
                                              tally() %>%
                                              pivot_wider(names_from = label, values_from = n, values_fill = 0)
                    
                        class_counts <<- list(
                            discrim = sum(training_data$label == "discrim"),
                            neutral = sum(training_data$label == "neutral")
                        )
                    
                        smoothing_factor <- 1 
                        total_vocab <- nrow(class_word_counts)
                    
                        if (!"discrim" %in% names(class_word_counts)) {
                            class_word_counts$discrim <<- 0
                        }
                        if (!"neutral" %in% names(class_word_counts)) {
                            class_word_counts$neutral <<- 0
                        }
                    
                        total_discrim_words <- sum(class_word_counts$discrim)
                        total_neutral_words <- sum(class_word_counts$neutral)
                    
                        word_probabilities <<- data.frame(
                            word = class_word_counts$words,
                            prob_discrim = (class_word_counts$discrim + smoothing_factor) / (total_discrim_words + smoothing_factor * total_vocab),
                            prob_neutral = (class_word_counts$neutral + smoothing_factor) / (total_neutral_words + smoothing_factor * total_vocab)
                        )
                    },


                    predict = function(message)
                    {
                        message_df <- data.frame(text = message, stringsAsFactors = FALSE)
                        
                        message_tokens <- unnest_tokens(message_df, 'words', 'text', token = "words") %>%
                                          filter(!words %in% splitted_stop_words & !grepl("\\d", words)) %>%
                                          pull(words)
                    
                        log_prob_discrim <- log(class_counts$discrim / sum(unlist(class_counts)))
                        log_prob_neutral <- log(class_counts$neutral / sum(unlist(class_counts)))
                    
                        for (word in message_tokens) {
                            if (word %in% word_probabilities$word) {
                                word_prob <- word_probabilities[word_probabilities$word == word, ]
                                log_prob_discrim <- log_prob_discrim + log(word_prob$prob_discrim)
                                log_prob_neutral <- log_prob_neutral + log(word_prob$prob_neutral)
                            } else {
                                unseen_word_count <<- unseen_word_count + 1
                            }
                        }
                    
                        return(ifelse(log_prob_discrim > log_prob_neutral, "discrim", "neutral"))
                    },


                    score = function(X_test, y_test)
                    {
                        predictions <- sapply(X_test, function(sentence) {
                            predict(sentence)
                        })

                        TP <- sum(predictions == "discrim" & y_test == "discrim")
                        TN <- sum(predictions == "neutral" & y_test == "neutral")
                        FP <- sum(predictions == "discrim" & y_test == "neutral")
                        FN <- sum(predictions == "neutral" & y_test == "discrim")

                        precision <- TP / (TP + FP)
                        recall <- TP / (TP + FN)
                        f1_score <- 2 * (precision * recall) / (precision + recall)
                        accuracy <- (TP + TN) / length(y_test)
                        
                        return(list(precision = precision, recall = recall, f1_score = f1_score, accuracy = accuracy))
                    }
))

# Example usage:
model <- naiveBayes()
model$fit(train$tweet, train$label)

model$score(test$tweet, test$label)

```
